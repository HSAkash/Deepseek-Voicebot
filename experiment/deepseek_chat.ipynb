{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    temperature=0.5,\n",
    "    keep_alive=-1,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_thinking_from_message(message:str)->str:\n",
    "    \"\"\"removes thinking from message\n",
    "    Args:\n",
    "        message (str): message\n",
    "    Returns:\n",
    "        str: message without thinking\n",
    "    \"\"\"\n",
    "    close_tag = \"</think>\"\n",
    "    tag_length = len(close_tag)\n",
    "    return message[message.find(close_tag) + tag_length:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm | (lambda x: remove_thinking_from_message(x.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How can I assist you today? ðŸ˜Š\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are an AI assistant. You are here to help me with my queries.\"\n",
    "QUERY_TEMPLATE = \"<question> {question} </question>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",SYSTEM_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", QUERY_TEMPLATE),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris. This city has a rich history and numerous landmarks, such as the Eiffel Tower, which are significant cultural and historical sites. After the separation of the monarchy from France in 1792, Paris became the administrative capital, but it remains the main political and economic hub for the entire country.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"What is the capital of France?\"\n",
    "messages = PROMPT_TEMPLATE.invoke(\n",
    "    {\n",
    "        \"question\": question,\n",
    "        \"chat_history\" : chat_history,\n",
    "    }\n",
    ")\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
